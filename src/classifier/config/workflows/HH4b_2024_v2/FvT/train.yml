# template:
# - model: path to model

# when run with
#   template/-template "model: path/to/model" path/to/this/file.yml
# the {model} will be replaced by path/to/model

main:
  module: train # run training task
  option:
    - --max-loaders 2 # use 2 workers to load dataset
    - --max-trainers 3 # use 3 workers to train

dataset:
  - module: HCR.FvT.TrainBaseline # use the baseline dataset for FvT training
    option:
      - --metadata coffea4bees/metadata/datasets_HH4b_2024_v2 # choose dataset
      - --max-workers 20 # use 20 workers to load ROOT files
      - --data-source detector # only use data (not mixed data or synthetic data)
      - --JCM-weight "" coffea4bees/analysis/weights/JCM/2024_v2/jetCombinatoricModel_SB_2024_v2.yml@@JCM_weights # set JCM weight, where the @@ is used to get the key JCM_weights inside the file
      - --friends "" coffea4bees/metadata/datasets_HH4b_2024_v2_classifier_input.json@@HCR_input # set input friend tree

model:
  - module: HCR.FvT.baseline.Train # use the baseline model for FvT
    option:
      - --kfolds 3 # use 3-fold
      - --kfold-seed FvT random # setup base seed to be ("FvT", "random")
      - --kfold-seed-offsets 0 # use seed ("FvT", "random", 0)
      # --kfold-seed-offsets 0-14 will use seed ("FvT", "random", 0), ... ("FvT", "random", 14) to train 15 models
      - --training FixedStep # setup training schedule
      # FixedStep is defined in config/scheduler
      - epoch: 20 # setup kwargs for FixedStep
        bs_init: 1024 # equivalent to use FixedStep(epoch=20, bs_init=1024)
      - --finetuning FixedStep # setup finetuning schedule
      - epoch: 1
        bs_init: 16384

setting:
  - module: IO # setup output directory
    option:
      - output: "{model}" # will be replaced by the template
